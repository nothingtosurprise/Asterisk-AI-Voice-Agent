# ═══════════════════════════════════════════════════════════════════════════
# Golden Baseline #2: Deepgram Voice Agent - Enterprise Cloud Agent
# ═══════════════════════════════════════════════════════════════════════════
#
# VALIDATED CONFIGURATION - Production-ready
#
# Requirements:
#   - DEEPGRAM_API_KEY in .env file
#   - OPENAI_API_KEY in .env (for agent's "Think" stage reasoning)
#   - Asterisk 18+ with ARI and AudioSocket modules
#
# Performance:
#   - Response time: <3 seconds (typically 1-2s)
#   - Audio quality: Excellent (Deepgram Aura TTS)
#   - Cost: ~$0.03 per minute (Deepgram pricing)
#
# Best for:
#   - Enterprise deployments requiring high quality
#   - Scenarios needing multi-step reasoning (Think stage)
#   - Cost-sensitive deployments (cheaper than OpenAI Realtime)
#   - Integration with Deepgram's analytics platform
#
# For detailed parameter explanations, see: docs/Configuration-Reference.md
# ═══════════════════════════════════════════════════════════════════════════

# Provider Selection
# The monolithic provider to use for this configuration
default_provider: "deepgram"

# Audio Transport
# "audiosocket" = TCP-based full-duplex audio (recommended for Deepgram)
# "externalmedia" = RTP-based audio transport (also works)
audio_transport: "audiosocket"

# Playback Mode
# "file" = File-based playback (more robust, recommended for Deepgram)
# "stream" = Real-time streaming playback (can be used once stable)
downstream_mode: "file"

# AudioSocket Configuration
# TCP listener for bidirectional audio from Asterisk
audiosocket:
  host: "0.0.0.0"              # Bind to all interfaces
  port: 8090                    # Standard AudioSocket port
  format: "ulaw"                # Audio format: ulaw (8kHz telephony standard)

# Barge-In (Interrupt Handling)
# Controls when user speech can interrupt AI responses
# NOTE: Currently disabled for Deepgram (server-side handling recommended)
barge_in:
  enabled: false                            # Disabled - Deepgram handles turn-taking
  initial_protection_ms: 400                # Protect first 400ms of greeting from echo
                                            # Range: 200-600ms. Higher = less echo sensitivity
  min_ms: 400                               # Minimum sustained speech to trigger interrupt
                                            # Range: 250-600ms. Lower = more responsive
  energy_threshold: 1800                    # RMS energy threshold for speech detection
                                            # Range: 1000-3000. Lower = more sensitive
  cooldown_ms: 1000                         # Ignore new interrupts for this duration
                                            # Range: 500-1500ms. Prevents rapid re-triggering
  post_tts_end_protection_ms: 250           # Guard time after AI finishes speaking
                                            # Range: 250-500ms. Prevents clipping user response

# Voice Activity Detection (VAD)
# Optional: Add a `vad:` block if you need utterance segmentation control
# See docs/Configuration-Reference.md for VAD configuration options
# Deepgram handles VAD server-side, so local VAD typically not needed

# Provider Configuration
# Deepgram Voice Agent API settings
providers:
  deepgram:
    enabled: true                                              # Enable this provider
    api_key: "${DEEPGRAM_API_KEY}"                             # API key from .env (NEVER hardcode!)
    
    # Model Configuration
    model: "nova-2-general"                                    # STT model: Deepgram Nova-2
                                                               # Options: nova-2-general, nova-2-phonecall, nova-2-meeting
    tts_model: "aura-asteria-en"                              # TTS voice: Deepgram Aura
                                                               # Options: aura-asteria-en, aura-luna-en, aura-stella-en,
                                                               #          aura-athena-en, aura-hera-en, aura-orion-en
    
    # AI Behavior
    greeting: "${DEEPGRAM_GREETING:-Hello, how can I help you today?}"
                                                               # Initial greeting
                                                               # Can override with DEEPGRAM_GREETING env var
                                                               # Can override per-call with AI_GREETING channel variable
    instructions: "${DEEPGRAM_INSTRUCTIONS:-You are a concise voice assistant. Respond in under 20 words and answer immediately.}"
                                                               # AI persona/behavior instructions
                                                               # Can override with DEEPGRAM_INSTRUCTIONS env var
                                                               # Can override per-call with AI_PERSONA channel variable
    
    # Audio Format Configuration
    input_encoding: "linear16"                                 # Format from Asterisk (PCM16)
                                                               # Deepgram prefers PCM16 for best quality
    input_sample_rate_hz: 8000                                 # Sample rate from Asterisk
    continuous_input: true                                     # Enable continuous audio streaming
                                                               # Required for real-time conversation
    
    # Output Audio Configuration
    output_encoding: "mulaw"                                   # Output format: μ-law for telephony
                                                               # Engine converts Deepgram's output to μ-law
    output_sample_rate_hz: 8000                                # Output sample rate for Asterisk

# LLM Configuration (Fallback/Default)
# These settings are used when providers don't specify their own
# For Deepgram Voice Agent, these are typically overridden by provider.instructions
llm:
  initial_greeting: "Hello, how can I help you today?"        # Default greeting
  prompt: "You are a concise and helpful voice assistant. Keep replies under 20 words unless asked for detail."
                                                               # Default persona
  model: "gpt-4o"                                              # Default model (used by Deepgram's Think stage)
