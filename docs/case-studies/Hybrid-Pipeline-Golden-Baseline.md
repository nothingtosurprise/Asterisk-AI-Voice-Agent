# Hybrid Pipeline Golden Baseline

**Status**: âœ… **VALIDATED - Production Ready**  
**Date**: October 28, 2025  
**Call ID**: 1761702190.2645  
**User Report**: "That worked perfectly, clean two way audio."

---

## Executive Summary

The **local_hybrid** pipeline represents the golden baseline for hybrid pipeline architectures, validating the modular STT â†’ LLM â†’ TTS approach with mixed local/cloud components. This configuration achieves clean two-way audio, proper turn-taking, and demonstrates the flexibility of hybrid architectures.

---

## Configuration

### Pipeline Definition

```yaml
active_pipeline: local_hybrid
audio_transport: externalmedia  # RTP transport (validated âœ…)

pipelines:
  local_hybrid:
    stt: local_stt        # Local Vosk
    llm: openai_llm       # Cloud OpenAI
    tts: local_tts        # Local Piper
    options:
      stt:
        chunk_ms: 160
        mode: stt
        stream_format: pcm16_16k
        streaming: true
      llm:
        base_url: https://api.openai.com/v1
        model: gpt-4o-mini
        max_tokens: 150
        temperature: 0.7
      tts:
        format:
          encoding: mulaw
          sample_rate: 8000
```

### Provider Configuration

```yaml
providers:
  local:
    enabled: true  # âš ï¸ CRITICAL - Must be enabled
    ws_url: ws://127.0.0.1:8765
    connect_timeout_sec: 2.0
    response_timeout_sec: 5.0
    chunk_ms: 320
    # Model paths
    stt_model: models/stt/vosk-model-en-us-0.22
    llm_model: models/llm/phi-3-mini-4k-instruct.Q4_K_M.gguf
    tts_voice: models/tts/en_US-lessac-medium.onnx
```

---

## Architecture

### Component Stack

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    CALLER (Î¼-law 8kHz)                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚ RTP
                      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          ExternalMedia RTP Server (ai-engine)           â”‚
â”‚  â€¢ Receives RTP from Asterisk                           â”‚
â”‚  â€¢ Decodes Î¼-law â†’ PCM16                                â”‚
â”‚  â€¢ Resamples 8kHz â†’ 16kHz                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚ PCM16 @ 16kHz
                      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   Pipeline Queue                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
                      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  LOCAL STT (Vosk) - ws://127.0.0.1:8765                 â”‚
â”‚  â€¢ Model: vosk-model-en-us-0.22 (16kHz native)          â”‚
â”‚  â€¢ Streaming recognition with partials                   â”‚
â”‚  â€¢ Privacy-focused, offline capable                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚ Transcript (text)
                      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  OPENAI LLM (Cloud) - api.openai.com                    â”‚
â”‚  â€¢ Model: gpt-4o-mini                                    â”‚
â”‚  â€¢ Max tokens: 150                                       â”‚
â”‚  â€¢ Temperature: 0.7                                      â”‚
â”‚  â€¢ Quality reasoning, fast responses                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚ Response (text)
                      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  LOCAL TTS (Piper) - ws://127.0.0.1:8765                â”‚
â”‚  â€¢ Voice: en_US-lessac-medium.onnx (22kHz native)       â”‚
â”‚  â€¢ Output: Î¼-law @ 8kHz (transcoded)                    â”‚
â”‚  â€¢ Privacy-focused, offline capable                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚ Audio (Î¼-law 8kHz)
                      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              PlaybackManager (ai-engine)                 â”‚
â”‚  â€¢ Writes audio file to disk                            â”‚
â”‚  â€¢ Sends Playback ARI command to Asterisk               â”‚
â”‚  â€¢ Manages gating (disables STT during playback)        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚ ARI Playback
                      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Asterisk PBX                          â”‚
â”‚  â€¢ Plays audio file via Announcer channel               â”‚
â”‚  â€¢ Sends PlaybackFinished event when complete           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚ RTP
                      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    CALLER (Î¼-law 8kHz)                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Performance Metrics

### Call Details

**Call ID**: 1761702190.2645  
**Duration**: ~30 seconds  
**Conversation**: Multi-turn with proper gating  
**Audio Quality**: Clean, no distortion  
**User Assessment**: "That worked perfectly, clean two way audio."

### Latency Measurements

| Component | Metric | Value | Notes |
|-----------|--------|-------|-------|
| **Greeting TTS** | First audio | 624 ms | Local Piper synthesis |
| **Greeting TTS** | Audio size | 14,861 bytes | ~1.8s of audio @ 8kHz Î¼-law |
| **Response 1 TTS** | Latency | 675 ms | "know what is your name" response |
| **Response 1 TTS** | Audio size | 26,285 bytes | ~3.2s of audio |
| **Response 2 TTS** | Latency | 1,459 ms | Longer response |
| **Response 2 TTS** | Audio size | 58,700 bytes | ~7.3s of audio |

### Key Observations

âœ… **Local STT Streaming**: Continuous partials ("huh", "know what", "know what is your name")  
âœ… **Gating Working**: Audio capture toggled correctly during TTS playback  
âœ… **PlaybackFinished Events**: Arriving properly, gating cleared on completion  
âœ… **Turn-Taking**: Clean conversation flow, no feedback loops  
âœ… **Local Processing**: Privacy-focused STT/TTS with cloud LLM quality

---

## Validation Evidence

### Startup Logs

```
âœ… Local pipeline adapters registered
   stt_factory=local_stt
   llm_factory=local_llm
   tts_factory=local_tts

âœ… STT model loaded: vosk-model-en-us-0.22 (16kHz native)
âœ… LLM model loaded: phi-3-mini-4k-instruct.Q4_K_M.gguf
âœ… TTS model loaded: en_US-lessac-medium.onnx (22kHz native)

âœ… Pipeline orchestrator initialized
   active_pipeline=local_hybrid
   healthy_pipelines=5
   unhealthy_pipelines=1
```

### Call Flow Logs

```
01:43:17 Pipeline runner started (local_hybrid)
01:43:17 Pipeline TTS adapter session opened
01:43:17 Local TTS audio chunk received (14,861 bytes, 624ms) â† Greeting
01:43:17 Local STT streaming started
01:43:19 ğŸ”Š TTS GATING - Audio capture enabled (gating cleared)
01:43:19 ğŸ”Š PlaybackFinished - Audio playback completed

[User speaks: "know what is your name"]
01:43:17 Local STT partial: "huh"
01:43:22 Local STT partial: "no"
01:43:22 Local STT partial: "know what"
01:43:22 Local STT partial: "know what is the"
01:43:22 Local STT partial: "know what is your name"

[OpenAI LLM processes, generates response]
01:43:25 Local TTS audio chunk received (26,285 bytes, 675ms)
01:43:28 ğŸ”Š TTS GATING - Audio capture enabled (gating cleared)
01:43:28 ğŸ”Š PlaybackFinished - Audio playback completed

[Continued conversation...]
01:43:35 Local TTS audio chunk received (58,700 bytes, 1,459ms)
01:43:42 ğŸ”Š TTS GATING - Audio capture enabled (gating cleared)
01:43:42 ğŸ”Š PlaybackFinished - Audio playback completed
```

---

## Critical Success Factors

### 1. Local Provider Enabled

**Required**: `providers.local.enabled: true`

**Why Critical**:
- If disabled, orchestrator uses placeholder adapters
- Placeholder adapters throw `NotImplementedError`
- Greeting fails, no audio produced

**Symptom if Disabled**:
```
NotImplementedError: Milestone7 placeholder STT adapter 'local_stt' 
is not implemented yet.
```

### 2. Local AI Server Running

**Container**: `local_ai_server` (Docker Compose)  
**WebSocket**: `ws://127.0.0.1:8765`  
**Health Check**: Port 8765 connectivity

**Models Required**:
- STT: `models/stt/vosk-model-en-us-0.22`
- LLM: `models/llm/phi-3-mini-4k-instruct.Q4_K_M.gguf`
- TTS: `models/tts/en_US-lessac-medium.onnx`

### 3. Transport Configuration

**Validated Transport**: ExternalMedia RTP  
**Why RTP**: Separate audio ingestion, no bridge conflicts  
**Config**: `audio_transport: externalmedia`

**Not Validated**: AudioSocket + Pipelines (bridge routing conflict)

### 4. Gating Implementation

**Fix Applied**: AAVA-28 (commit 181b210)  
**Behavior**: Pipeline audio ingestion checks `audio_capture_enabled`  
**Result**: No feedback loop, agent doesn't hear itself

---

## Use Cases

### When to Use local_hybrid

âœ… **Privacy Requirements**
- Audio processing stays on-premises
- Only text (LLM) goes to cloud
- Compliant with data sovereignty requirements

âœ… **Cost Optimization**
- Local STT/TTS eliminates per-minute API costs
- Cloud LLM only when reasoning needed
- Reduces bandwidth (audio stays local)

âœ… **Offline Capability**
- STT/TTS work without internet
- Graceful degradation if LLM unavailable
- Edge deployment scenarios

âœ… **Quality + Privacy Balance**
- Local audio quality (Vosk, Piper)
- Cloud LLM reasoning (OpenAI gpt-4o-mini)
- Best of both worlds

### When NOT to Use local_hybrid

âŒ **Resource Constrained Environments**
- Vosk STT: ~200MB RAM
- Piper TTS: ~100MB RAM
- Phi-3 LLM: ~2GB RAM (if using local LLM)

âŒ **Simplicity Priority**
- Requires local_ai_server container
- Additional model management
- More moving parts than cloud-only

âŒ **State-of-the-Art Requirements**
- Cloud STT (Deepgram) more accurate
- Cloud TTS (Deepgram, OpenAI) better quality
- Use hybrid_support instead

---

## Alternative Hybrid Configurations

### hybrid_support (Cloud-Based)

**Validated**: âœ… Call 1761698845.2619

```yaml
pipelines:
  hybrid_support:
    stt: deepgram_stt    # Cloud
    llm: openai_llm      # Cloud
    tts: deepgram_tts    # Cloud
```

**Pros**:
- Best quality (state-of-the-art models)
- No local resources needed
- Simpler deployment

**Cons**:
- Higher costs (per-minute API fees)
- Privacy concerns (audio to cloud)
- Requires internet connectivity

### local_only (Fully Local)

**Configuration**:
```yaml
pipelines:
  local_only:
    stt: local_stt       # Local
    llm: local_llm       # Local (Phi-3)
    tts: local_tts       # Local
```

**Pros**:
- Complete privacy
- Zero API costs
- Offline capable

**Cons**:
- Lower LLM quality vs cloud
- Higher resource usage (LLM inference)
- Slower responses (local LLM inference time)

---

## Troubleshooting

### Issue: "Pipeline greeting unexpected failure"

**Cause**: Local provider not enabled

**Fix**:
```yaml
providers:
  local:
    enabled: true  # Must be true
```

**Verify**:
```bash
docker logs ai_engine | grep "Local pipeline adapters registered"
```

### Issue: "Connection rejected (400 Bad Request)"

**Cause**: Local AI server not responding or wrong protocol

**Check Server**:
```bash
docker logs local_ai_server | grep "server listening"
# Should show: server listening on 0.0.0.0:8765
```

**Check Health**:
```bash
docker ps | grep local_ai_server
# Should show: (healthy)
```

### Issue: No audio playback

**Causes**:
1. Gating not working (audio ingestion bypassing checks)
2. PlaybackManager not receiving TTS audio
3. File playback path broken

**Diagnostics**:
```bash
# Check for gating logs
docker logs ai_engine | grep "audio_capture_enabled"

# Check for TTS synthesis
docker logs ai_engine | grep "Local TTS audio chunk"

# Check for playback
docker logs ai_engine | grep "PlaybackFinished"
```

---

## Related Documentation

- **Transport Compatibility**: [docs/Transport-Mode-Compatibility.md](./Transport-Mode-Compatibility.md)
- **Gating Fix**: Linear AAVA-28, commits 181b210, fbaaf2e
- **Local Adapters**: [src/pipelines/local.py](../src/pipelines/local.py)
- **Pipeline Orchestrator**: [src/pipelines/orchestrator.py](../src/pipelines/orchestrator.py)

---

## Commits

**Golden Baseline Validation**:
- b0266b8: Enable local provider for local_hybrid pipeline
- b87b893: Switch to local_hybrid for testing
- c6a951d: Add local_hybrid pipeline configuration
- 12f088f: Logging improvements (channel variables, recording)
- 9ab0df1: Fix hybrid_support base_url
- 3aed2d9: Switch to hybrid_support (reverted)

**Critical Fixes (AAVA-28)**:
- 181b210: Pipeline gating enforcement
- fbaaf2e: Fallback safety margin (2.5s for pipelines)
- 294e55e: Deepgram STT streaming
- 0f71c74: Pipeline audio codec management
- cc8d672: Transport compatibility documentation

---

## Production Recommendations

### Deployment Checklist

- [ ] Local AI server container running and healthy
- [ ] Models downloaded and accessible in volumes
- [ ] `providers.local.enabled: true` in config
- [ ] ExternalMedia RTP transport configured
- [ ] Gating fixes applied (AAVA-28)
- [ ] Test call verifies clean two-way audio

### Monitoring

**Key Metrics**:
- Local STT latency (streaming partials)
- OpenAI LLM response time
- Local TTS synthesis latency
- Gating toggle frequency
- PlaybackFinished event timing

**Health Checks**:
- Local AI server WebSocket connectivity (port 8765)
- Container health status (Docker)
- Model loading success on startup

### Scaling Considerations

**Single Local Server Limits**:
- ~10-20 concurrent calls (depends on hardware)
- CPU-bound (STT/TTS/LLM inference)
- Consider horizontal scaling (multiple servers)

**Cloud LLM Scaling**:
- OpenAI handles concurrency
- Rate limits: 10,000 RPM (gpt-4o-mini)
- Monitor token usage for cost control

---

## GA v4.0 Status

**Pipeline**: local_hybrid  
**Status**: âœ… **VALIDATED - Production Ready**  
**Designation**: **Golden Baseline for Hybrid Pipelines**  

**Validation Date**: October 28, 2025  
**Validator**: User test call  
**Result**: "That worked perfectly, clean two way audio."

**Next Steps**:
- Document alternative configurations
- Create migration guides (cloud â†’ hybrid)
- Performance benchmarking suite
- Cost analysis (local vs cloud components)
